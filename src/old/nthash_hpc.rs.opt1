// homopolymer compression version of ntHash1,
// which simulatenously HPC and record original offsets of sequences
//
//
// single-file version
// code adapted from ntHash1 and mainly from Luiz Irber's Rust crate port
// kept only the canonical version (no 'forward')


const MAXIMUM_K_SIZE: usize = u32::max_value() as usize;

#[derive(thiserror::Error, Debug)]
pub enum Error {
    #[error("K size {ksize} is out of range for the given sequence size {seq_size}")]
    KSizeOutOfRange { ksize: usize, seq_size: usize },
    #[error("K size {0} cannot exceed the size of a u32 {MAXIMUM_K_SIZE}")]
    KSizeTooBig(usize),
}

pub type Result<T> = std::result::Result<T, Error>;

const H_LOOKUP: [u64; 256] = {
    let mut lookup = [1; 256];
    lookup[b'A' as usize] = 0x3c8b_fbb3_95c6_0474;
    lookup[b'C' as usize] = 0x3193_c185_62a0_2b4c;
    lookup[b'G' as usize] = 0x2032_3ed0_8257_2324;
    lookup[b'T' as usize] = 0x2955_49f5_4be2_4456;
    lookup[b'N' as usize] = 0;
    lookup
};

const RC_LOOKUP: [u64; 256] = {
    let mut lookup = [1; 256];
    lookup[b'A' as usize] = 0x2955_49f5_4be2_4456;
    lookup[b'C' as usize] = 0x2032_3ed0_8257_2324;
    lookup[b'G' as usize] = 0x3193_c185_62a0_2b4c;
    lookup[b'T' as usize] = 0x3c8b_fbb3_95c6_0474;
    lookup[b'N' as usize] = 0;
    lookup
};

#[inline(always)]
fn h(c: u8) -> u64 {
    let val = H_LOOKUP[c as usize];
    if val == 1 {
        panic!("Non-ACGTN nucleotide encountered! {}", c as char)
    }
    val
}

#[inline(always)]
fn rc(nt: u8) -> u64 {
    let val = RC_LOOKUP[nt as usize];
    if val == 1 {
        panic!("Non-ACGTN nucleotide encountered! {}", nt as char)
    }
    val
}

/// An efficient iterator for returning rev-comp aware hashes in HPC space, keeping only those
/// below a hash bound. That's a very specialized application, useful for rust-mdbg.
///
/// Since it implements the `Iterator` trait it also
/// exposes many other useful methods. In this example we use `collect` to
/// generate all hashes and put them in a `Vec<u64>`.
/// ```
///     use rust_seq2kminmers::NtHashHPCIterator;
///
///     # fn main() {
///     let seq = b"ACTGCACATGATGAGTAGATGATGATGATGATGATATGATGATAT";
///     let density = 0.1;
///     let hash_bound = ((density as f64) * (u64::max_value() as f64)) as u64;
///     let iter = NtHashHPCIterator::new(seq, 4, hash_bound).unwrap();
///     let hashes: Vec<(usize,u64)> = iter.collect();
///     assert_eq!(hashes,
///                vec![(0, 1693589515812555183), (6, 876319423165292601), (13,771890730643629033), (16, 826464090118103095), (33, 1245321008145464903), (34,1193606442387228521)]);
///     # }
/// ```

#[derive(Debug)]
pub struct NtHashHPCIterator<'a> {
    seq: &'a [u8],
    k: usize,
    fh: u64,
    rh: u64,
    current_idx_plus_k: usize,
    seq_len: usize,
    hash_bound: u64,
    h_buffer: Vec<u64>,
    rc_buffer: Vec<u64>,
    idx_buffer: Vec<usize>,
    buffer_pos: usize,
    after_first_iter: bool
}

impl<'a> NtHashHPCIterator<'a> {
    /// Creates a new NtHashHPCIterator with internal state properly initialized.
    pub fn new(seq: &'a [u8], k: usize, hash_bound: u64) -> Result<NtHashHPCIterator<'a>> {
        let seq_len = seq.len();
        if k > seq_len {
            return Err(Error::KSizeOutOfRange {
                ksize: k,
                seq_size: seq.len(),
            });
        }
        if k > MAXIMUM_K_SIZE {
            return Err(Error::KSizeTooBig(k));
        }
        let mut fh = 0;
        let mut j = 0; // current position in non-HPC space
        let mut i = 0; // current position in HPC space
        let mut prev;
        let mut prev_j = 0;
        let mut v;

        let mut h_buffer:   Vec<u64>   = vec![0; k+1];
        let mut rc_buffer:  Vec<u64>   = vec![0; k+1];
        let mut idx_buffer: Vec<usize> = vec![0; k+1];
        // pre-compute hash of first kmer in HPC space
        while i < k && j < seq_len
        {
            v = seq[j];
            let hv = h(v);
            h_buffer[i] = hv;
            idx_buffer[i] = j;
            fh ^= hv.rotate_left((k - i - 1) as u32);
            i += 1;
            // HPC on the fly
            prev = v;
            prev_j = j;
            while j < seq_len &&  seq[j] == prev { j += 1};
        }
        // if sequence is shorter than k in HPC space: hash will be incorrect and i<k , but that's ok, 
        // hash is only returned later in the iterator where proper length checks are performed
        assert!( (j >= seq_len && i < k) || (j < seq_len && i==k) );

        // at this point just assume we're at position i==k in HPC space, j in non-HPC space,
        // read the sequence backwards to get hash of reverse complement
        i -= 1; 
        j = prev_j;
        let k_in_non_hpc_space = j;
        let mut rh = 0;
        loop
        {
            v = seq[j];
            let rcv = rc(v);
            rc_buffer[i] = rcv;
            rh ^= rcv.rotate_left(i as u32);
            if i == 0 { break;}
            i -= 1;
            // HPC on the fly
            prev = v;
            while j > 0 && seq[j] == prev { j -= 1};
        }

        Ok(NtHashHPCIterator {
            seq,
            k,
            fh,
            rh,
            current_idx_plus_k: k_in_non_hpc_space,
            seq_len,
            hash_bound,
            h_buffer,
            rc_buffer,
            idx_buffer,
            buffer_pos : 0,
            after_first_iter: false,
        })
    }
}

impl<'a> Iterator for NtHashHPCIterator<'a> {
    type Item = (usize,u64);


    fn next(&mut self) -> Option<(usize,u64)> {
        let mut hash;
        let mut prev_current_idx;
        loop
        {
            if self.after_first_iter {
                //let i = self.current_idx - 1;
                //let seqi = self.seq[i];
                let h_seqi  = self.h_buffer [(self.buffer_pos-1) % (self.k+1)];
                let rc_seqi = self.rc_buffer[(self.buffer_pos-1) % (self.k+1)];
                //let seqk = self.seq[self.current_idx_plus_k];
                let h_seqk  = self.h_buffer [(self.buffer_pos+self.k-1) % (self.k+1)];
                let rc_seqk = self.rc_buffer[(self.buffer_pos+self.k-1) % (self.k+1)];

                self.fh = self.fh.rotate_left(1) ^ h_seqi.rotate_left(self.k as u32) ^ h_seqk;

                self.rh = self.rh.rotate_right(1)
                    ^ rc_seqi.rotate_right(1)
                    ^ rc_seqk.rotate_left(self.k as u32 - 1);

                 //println!(" h_seqi {} rc_seqk {}", h_seqi,rc_seqk);
            }
            
            hash = u64::min(self.rh, self.fh);

            // update (current,current+k) pointers to next positions in HPC space
            let prev = self.seq[self.current_idx_plus_k];
            prev_current_idx = self.idx_buffer[self.buffer_pos % (self.k+1)];
            while self.current_idx_plus_k < self.seq_len  && self.seq[self.current_idx_plus_k] == prev 
            {
                self.current_idx_plus_k += 1;
            }

            if self.current_idx_plus_k >= self.seq_len - 1 {
                return None;
            };

            let v = self.seq[self.current_idx_plus_k];
            self.h_buffer  [(self.buffer_pos+self.k) % (self.k+1)] = h(v);
            self.rc_buffer [(self.buffer_pos+self.k) % (self.k+1)] = rc(v);
            self.idx_buffer[(self.buffer_pos+self.k) % (self.k+1)] = self.current_idx_plus_k;
            self.buffer_pos += 1;
            self.after_first_iter = true; 

            if hash <= self.hash_bound { break; }
        }
        Some((prev_current_idx, hash))
    }

    fn size_hint(&self) -> (usize, Option<usize>) {
        let size_hint = (self.seq_len - self.k + 1) * (((u64::max_value() as f64) / (self.hash_bound as f64)) as u64) as usize; // rough estimation
        (size_hint, Some(size_hint)) 
    }
}
